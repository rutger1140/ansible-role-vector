# {{ ansible_managed }}

# Set global options
data_dir = "/var/lib/vector"

# Forwarding logs to Logtail.com
# ------------------------------

[sources.logtail_nginx_logs_{{ vector_logtail_bearer_token }}]
type = "file"
read_from = "beginning"
ignore_older_secs = 600
include = ["{{ vector_nginx_logs_path }}*.log"]
exclude = []

[transforms.logtail_nginx_parser_{{ vector_logtail_bearer_token }}]
type = "remap"
inputs = ["logtail_nginx_logs_{{ vector_logtail_bearer_token }}"]
source = '''
del(.source_type)
.dt = del(.timestamp)
.nginx = parse_regex(.message, r'^\s*(-|(?P<client>\S+))\s+\-\s+(-|(?P<user>\S+))\s+\[(?P<timestamp>.+)\]\s+"(?P<request>(?P<method>\w+)\s+(?P<path>\S+)\s+(?P<protocol>\S+))"\s+(?P<status>\d+)\s+(?P<size>\d+)\s+"(-|(?P<referrer>.+))"\s+"(-|(?P<agent>.+))"\s*') ??
    parse_regex(.message, r'^\s*(?P<timestamp>.+)\s+\[(?P<severity>\w+)\]\s+(?P<pid>\d+)\#(?P<tid>\d+):\s+\*(?P<cid>\d+)\s+(?P<message>.*)(?:,\s+client:\s+(?P<client>[^,z]+))(?:,\s+server:\s+(?P<server>[^,z]+))(?:,\s+request:\s+"(?P<request>[^"]+)")(?:,\s+subrequest:\s+"(?P<subrequest>[^"]+)")?(?:,\s+upstream:\s+"(?P<upstream>[^"]+)")?(?:,\s+host:\s+"(?P<host>[^"]+)")(?:,\s+referrer:\s+"(?P<referrer>[^"]+)")?\s*') ??
    parse_nginx_log(.message, format: "combined") ??
    parse_nginx_log(.message, format: "error") ??
    {}

if .nginx != {} {
  .platform = "Nginx"
  .level = del(.nginx.severity)
  .message = del(.nginx.message)

  if is_null(.message) { del(.message) }
  if exists(.nginx.timestamp) {
    .dt = format_timestamp!(
      parse_timestamp(.nginx.timestamp, "%d/%b/%Y:%T %z") ??
        parse_timestamp(.nginx.timestamp, "%Y/%m/%d %T") ??
        .dt,
      "%+"
    )

    del(.nginx.timestamp)
  }

  if is_string(.nginx.status) { .nginx.status = to_int(.nginx.status) ?? .nginx.status }
  if is_string(.nginx.size) { .nginx.size = to_int(.nginx.size) ?? .nginx.size }
  if is_string(.nginx.cid) { .nginx.cid = to_int(.nginx.cid) ?? .nginx.cid }
  if is_string(.nginx.pid) { .nginx.pid = to_int(.nginx.pid) ?? .nginx.pid }
  if is_string(.nginx.tid) { .nginx.tid = to_int(.nginx.tid) ?? .nginx.tid }

  if is_null(.nginx.subrequest) { del(.nginx.subrequest) }
  if is_null(.nginx.upstream) { del(.nginx.upstream) }
  if is_null(.nginx.referrer) { del(.nginx.referrer) }

  # Set nginx client as client_string
  if exists(.nginx.client) { .client = .nginx.client }

} else {
  del(.nginx)
}
'''

[sources.logtail_auth_log_logs_{{ vector_logtail_bearer_token }}]
type = "file"
read_from = "beginning"
ignore_older_secs = 600
include = ["/var/log/auth.log"]
exclude = []

[transforms.logtail_auth_log_parser_{{ vector_logtail_bearer_token }}]
type = "remap"
inputs = ["logtail_auth_log_logs_{{ vector_logtail_bearer_token }}"]
source = '''
del(.source_type)
.dt = del(.timestamp)
.auth_log = parse_linux_authorization(.message) ?? {}

if .auth_log != {} {
  .platform = "Linux Authorization"
  .dt = del(.auth_log.timestamp)
  .message = del(.auth_log.message)

  # extract message metadata
  tmp = to_string(.message) ?? ""

  ips = parse_regex_all!(tmp, r'\b(?P<ip>(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))\b')
  if exists(ips[0].ip) { .message_metadata.ipv4_1 = ips[0].ip; tmp = replace(tmp, string!(ips[0].ip), "") }
  if exists(ips[1].ip) { .message_metadata.ipv4_2 = ips[1].ip; tmp = replace(tmp, string!(ips[1].ip), "") }
  if exists(ips[2].ip) { .message_metadata.ipv4_3 = ips[2].ip; tmp = replace(tmp, string!(ips[2].ip), "") }
  if exists(ips[3].ip) { .message_metadata.ipv4_4 = ips[3].ip; tmp = replace(tmp, string!(ips[3].ip), "") }
  if exists(ips[4].ip) { .message_metadata.ipv4_5 = ips[4].ip; tmp = replace(tmp, string!(ips[4].ip), "") }

  # we match only full IPv6 addresses
  ipv6s = parse_regex_all!(tmp, r'\b(?P<ip>(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4})\b')
  if exists(ipv6s[0].ip) { .message_metadata.ipv6_1 = ipv6s[0].ip; tmp = replace(tmp, string!(ipv6s[0].ip), "") }
  if exists(ipv6s[1].ip) { .message_metadata.ipv6_2 = ipv6s[1].ip; tmp = replace(tmp, string!(ipv6s[1].ip), "") }
  if exists(ipv6s[2].ip) { .message_metadata.ipv6_3 = ipv6s[2].ip; tmp = replace(tmp, string!(ipv6s[2].ip), "") }
  if exists(ipv6s[3].ip) { .message_metadata.ipv6_4 = ipv6s[3].ip; tmp = replace(tmp, string!(ipv6s[3].ip), "") }
  if exists(ipv6s[4].ip) { .message_metadata.ipv6_5 = ipv6s[4].ip; tmp = replace(tmp, string!(ipv6s[4].ip), "") }

  numbers = parse_regex_all!(tmp, r'(?P<num>\b\d+(?:\.\d+)?\b)')
  if exists(numbers[0].num) { .message_metadata.param1 = to_int(numbers[0].num) ?? to_float(numbers[0].num) ?? null }
  if exists(numbers[1].num) { .message_metadata.param2 = to_int(numbers[1].num) ?? to_float(numbers[1].num) ?? null }
  if exists(numbers[2].num) { .message_metadata.param3 = to_int(numbers[2].num) ?? to_float(numbers[2].num) ?? null }
  if exists(numbers[3].num) { .message_metadata.param4 = to_int(numbers[3].num) ?? to_float(numbers[3].num) ?? null }
  if exists(numbers[4].num) { .message_metadata.param5 = to_int(numbers[4].num) ?? to_float(numbers[4].num) ?? null }
  if exists(numbers[5].num) { .message_metadata.param6 = to_int(numbers[5].num) ?? to_float(numbers[5].num) ?? null }
  if exists(numbers[6].num) { .message_metadata.param7 = to_int(numbers[6].num) ?? to_float(numbers[6].num) ?? null }
  if exists(numbers[7].num) { .message_metadata.param8 = to_int(numbers[7].num) ?? to_float(numbers[7].num) ?? null }
  if exists(numbers[8].num) { .message_metadata.param9 = to_int(numbers[8].num) ?? to_float(numbers[8].num) ?? null }
  if exists(numbers[9].num) { .message_metadata.param10 = to_int(numbers[9].num) ?? to_float(numbers[9].num) ?? null }

  # Set ipv4 as client_string
  if exists(.message_metadata.ipv4_1) { .client = .message_metadata.ipv4_1 }

} else {
  del(.auth_log)
}
'''

[sources.logtail_fail2ban_logs_{{ vector_logtail_bearer_token }}]
type = "file"
read_from = "beginning"
ignore_older_secs = 600
include = ["/var/log/fail2ban.log"]
exclude = []

[transforms.logtail_fail2ban_parser_{{ vector_logtail_bearer_token }}]
type = "remap"
inputs = ["logtail_fail2ban_logs_{{ vector_logtail_bearer_token }}"]
source = '''
del(.source_type)
.dt = del(.timestamp)
.fail2ban = parse_regex(.message, r'^(?P<time>\d{4}\-\d{2}\-\d{2}\s\d{2}:\d{2}:\d{2}),\d{3}\s(.*):\s(?P<type>[A-Z]*)\s+\[(?P<jail>[^\]]+)\]\s+(?P<action>(\w+))\s+(?P<client>((?:[0-9]{1,3}\.){3}[0-9]{1,3}))(.*)$') ??
{}

if .fail2ban != {} {
  .platform = "Fail2ban"

  if exists(.fail2ban.time) {
    .dt = parse_timestamp(.fail2ban.time, "%Y/%m/%d %H:%M:%S") ?? now()

    del(.fail2ban.time)
  }

  # Set fail2ban client as client_string
  if exists(.fail2ban.client) { .client = .fail2ban.client }

} else {
  del(.fail2ban)
}
'''

[sources.logtail_haproxy_logs_{{ vector_logtail_bearer_token }}]
type = "file"
read_from = "beginning"
ignore_older_secs = 600
include = ["/var/log/haproxy.log"]
exclude = []

[transforms.logtail_haproxy_parser_{{ vector_logtail_bearer_token }}]
type = "remap"
inputs = ["logtail_haproxy_logs_{{ vector_logtail_bearer_token }}"]
source = '''
del(.source_type)
.dt = del(.timestamp)
.haproxy = parse_regex(.message, r'^(?P<syslog>([A-Z]{1}[a-z]{2}\s*\d{0,2}\s*\d{2}:\d{2}:\d{2}))\s*(?P<syslog_host>[a-z]*-[a-z]*-[a-z0-9]*)\s*(?P<ps>\w+)\[(?P<pid>\d+)\]:\s*((?P<c_ip>[\w\.]+):(?P<c_port>\d+))\s*\[(?P<time>.+)\]\s*(?P<f_end>[\w\~-]+)\s*(?P<b_end>[\w-]+)/(?P<b_server>[<>\w\.-]+)\s*(?P<tq>\d+)/(?P<tw>[\d-]+)/(?P<tc>[\d-]+)/(?P<tr>[\d-]+)/(?P<tt>[\d-]+)\s*(?P<status_code>\d+)\s*(?P<bytes>\d+)\s*(?P<req_cookie>\S?)\s*(?P<res_cookie>\S?)\s*(?P<t_state>[\w-]+)\s*(?P<actconn>\d+)/(?P<feconn>\d+)/(?P<beconn>\d+)/(?P<srv_conn>\d+)/(?P<retries>\d+)\s*(?P<srv_queue>\d+)/(?P<backend_queue>\d+)\s*"(?P<request>[^"]*)"') ??
{}

if .haproxy != {} {
  .platform = "HAProxy"

  if exists(.haproxy.time) {
    .dt = parse_timestamp(.haproxy.time, "%d/%b/%Y:%H:%M:%S.%f") ?? now()

    del(.haproxy.time)
  }

  if is_string(.haproxy.status_code) { .haproxy.status_code = to_int(.haproxy.status_code) ?? .haproxy.status_code }
  if exists(.haproxy.c_port) { del(.haproxy.c_port) }
  if exists(.haproxy.actconn) { del(.haproxy.actconn) }
  if exists(.haproxy.beconn) { del(.haproxy.beconn) }
  if exists(.haproxy.feconn) { del(.haproxy.feconn) }
  if exists(.haproxy.pid) { del(.haproxy.pid) }
  if exists(.haproxy.ps) { del(.haproxy.ps) }
  if exists(.haproxy.req_cookie) { del(.haproxy.req_cookie) }
  if exists(.haproxy.res_cookie) { del(.haproxy.res_cookie) }
  if exists(.haproxy.retries) { del(.haproxy.retries) }
  if exists(.haproxy.srv_conn) { del(.haproxy.srv_conn) }
  if exists(.haproxy.srv_queue) { del(.haproxy.srv_queue) }
  if exists(.haproxy.syslog_host) { del(.haproxy.syslog_host) }
  if exists(.haproxy.tc) { del(.haproxy.tc) }
  if exists(.haproxy.tq) { del(.haproxy.tq) }
  if exists(.haproxy.tr) { del(.haproxy.tr) }
  if exists(.haproxy.tt) { del(.haproxy.tt) }
  if exists(.haproxy.tw) { del(.haproxy.tw) }

  # Set haproxy client as client_string
  if exists(.haproxy.c_ip) { .client = .haproxy.c_ip }

} else {
  del(.haproxy)
}
'''

[sinks.logtail_http_sink_{{ vector_logtail_bearer_token }}]
type = "http"
uri = "https://in.logtail.com/"
encoding.codec = "json"
auth.strategy = "bearer"
auth.token = "{{ vector_logtail_bearer_token }}"
inputs = [
  "logtail_nginx_parser_{{ vector_logtail_bearer_token }}",
  "logtail_auth_log_parser_{{ vector_logtail_bearer_token }}",
  "logtail_fail2ban_parser_{{ vector_logtail_bearer_token }}",
  "logtail_haproxy_parser_{{ vector_logtail_bearer_token }}"
]
